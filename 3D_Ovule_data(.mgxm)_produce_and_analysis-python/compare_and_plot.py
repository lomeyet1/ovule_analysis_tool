#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Script for comparing and visualizing aggregated ovule data (generated by aggregate_data.py) between two sources.
Creates scatter plots with statistical comparisons and exports summary statistics.

author: Ziqiang Luo
date: 2025-04-13
usage: python compare_and_plot.py <folder1_path> <folder2_path> [output_folder]
"""

import argparse
import os
import sys
import subprocess
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import ttest_ind


# Check and install required packages if missing
def install_packages():
    """Install required Python packages if they're not available."""
    required_packages = {
        'pandas': 'pandas',
        'numpy': 'numpy',
        'matplotlib': 'matplotlib',
        'scipy': 'scipy'
    }

    for module, package in required_packages.items():
        try:
            __import__(module)
        except ImportError:
            print(f"Installing required package: {package}")
            subprocess.check_call([sys.executable, "-m", "pip", "install", package])


def get_aggregated_data(folder):
    """
    Load aggregated data from the specified folder.

    Args:
        folder (str): Path to the folder containing aggregated data

    Returns:
        pd.DataFrame: Loaded aggregated data
    """
    aggregation_folder = os.path.join(folder, "python_export_data_aggregated")

    # Find and load the first file starting with "aggregated_data"
    for file_name in os.listdir(aggregation_folder):
        if file_name.startswith("aggregated_data"):
            df = pd.read_csv(
                os.path.join(aggregation_folder, file_name),
                header=0,
                comment='#'
            )
            return df

    raise FileNotFoundError(f"No aggregated data file found in {aggregation_folder}")


def calculate_statistics(data, i):
    """
    Calculate and plot statistics for a dataset.

    Args:
        data (list/np.array): Data values to analyze
        i (int): Position index for plotting

    Returns:
        tuple: (average, standard_deviation)
    """
    confidence_level = 1.96  # For 95% confidence interval

    avg = np.mean(data)
    std_dev = np.std(data, ddof=1)  # Sample standard deviation
    sample_size = len(data)
    error_margin = confidence_level * (std_dev / np.sqrt(sample_size))

    # Plot error bars and average line
    plt.errorbar(i + 1, avg, yerr=error_margin, color='black', capsize=6)
    plt.hlines(avg, xmin=i + 0.8, xmax=i + 1.2, colors='black', linestyles='-')

    return avg, std_dev


def plot_results(type_df, plot_type, sources, output_folder):
    """
    Generate comparison plots and statistics for different data types.

    Args:
        type_df (pd.DataFrame): Data to plot
        plot_type (str): Type of data being plotted ('tissue' or 'combine_tissue')
        sources (list): List of two source names being compared
        output_folder (str): Output directory path

    Returns:
        pd.DataFrame: Statistics table with comparison results
    """
    abbreviation_order = type_df["abbreviation"].unique()
    source1 = sources[0]
    source2 = sources[1]
    # source1 = sources[0].split('_')[-2]
    # source2 = sources[1].split('_')[-2]
    statistics_table = pd.DataFrame()

    # Create output directories if they don't exist
    os.makedirs(output_folder, exist_ok=True)
    data_for_plot_folder = os.path.join(output_folder, "data_for_plot")
    os.makedirs(data_for_plot_folder, exist_ok=True)


    image_number = 1  # Counter for sequential file naming

    for data_type in type_df.columns[5:]:  # Skip metadata columns
        x_positions1, x_positions2 = [], []
        x_labels = []
        plot_data1, plot_data2 = [], []
        p_values = []
        data_for_plot = pd.DataFrame()
        i = 0  # Position counter for x-axis

        plt.figure(figsize=(10, 8))

        for structure in abbreviation_order:
            # Get data for both sources
            mask1 = (type_df["abbreviation"] == structure) & (type_df["Source"] == sources[0])
            type_data1 = type_df.loc[mask1, data_type].tolist()

            mask2 = (type_df["abbreviation"] == structure) & (type_df["Source"] == sources[1])
            type_data2 = type_df.loc[mask2, data_type].tolist()

            if not type_data1 or not type_data2:
                continue

            # len1 = len(type_data1)
            # len2 = len(type_data2)
            # max_len = max(len1,len2)
            # if len1 != len2:
            #     print(data_type," ", structure, " ", len1, " ", len2)
            #     print(type_data1)
            #     print(type_data2)
            # if len1 > len2:
            #     type_data2 = np.pad(type_data2, (0, max_len - len2),
            #                          mode='constant', constant_values=np.nan)
            # elif len1 < len2:
            #     type_data1 = np.pad(type_data1, (0, max_len - len1),
            #                          mode='constant', constant_values=np.nan)

            data_for_plot = pd.concat([data_for_plot, pd.DataFrame({f"{source1} {structure}": type_data1})], axis=1)
            data_for_plot = pd.concat([data_for_plot, pd.DataFrame({f"{source2} {structure}": type_data2})], axis=1)

            # Combine data for plotting
            plot_data1.extend(type_data1)
            plot_data2.extend(type_data2)

            # Calculate p-value using t-test
            p_value = ttest_ind(type_data1, type_data2)[1]
            p_values.append(p_value)

            # Calculate and plot statistics for source 1
            num_samples1 = len(type_data1)
            x_positions1.extend([i + 1 + (j - num_samples1 / 2) * 0.001 for j in range(num_samples1)])
            avg, std_dev = calculate_statistics(type_data1, i)

            # Record statistics for source 1
            statistics_table.loc[i, ["Source", "structure", "sample number"]] = [
                source1, structure, num_samples1
            ]

            # Handle unit scaling for display
            avg_std_type = data_type
            scale = 1
            if data_type in ["Area (μm²)", "Volume (μm³)"]:
                avg_std_type = f"{data_type.split('(')[0]}(10⁴ {data_type.split('(')[1]}"
                scale = 10000

            if avg_std_type not in statistics_table.columns:
                statistics_table.insert(3, avg_std_type, None)

            statistics_table.loc[i, [
                avg_std_type,
                f"avg. {data_type}",
                f"std_dev. {data_type}",
                f"p_values {data_type}"
            ]] = [
                f"{(avg / scale).round(2)} ± {(std_dev / scale).round(1)}",
                avg,
                std_dev,
                ""
            ]
            i += 1

            # Calculate and plot statistics for source 2
            num_samples2 = len(type_data2)
            x_positions2.extend([i + 1 + (j - num_samples2 / 2) * 0.001 for j in range(num_samples2)])
            avg, std_dev = calculate_statistics(type_data2, i)

            # Record statistics for source 2
            statistics_table.loc[i, ["Source", "structure", "sample number"]] = [
                source2, structure, num_samples2
            ]
            statistics_table.loc[i, [
                avg_std_type,
                f"avg. {data_type}",
                f"std_dev. {data_type}",
                f"p_values {data_type}"
            ]] = [
                f"{(avg / scale).round(2)} ± {(std_dev / scale).round(2)}",
                avg,
                std_dev,
                p_value
            ]
            i += 1

            x_labels.extend([f"{source1} {structure}", f"{source2} {structure}"])

        # Create scatter plot
        plt.scatter(
            x_positions1, plot_data1,
            color='orange', marker='o', alpha=0.8,
            facecolors='none', label=sources[0]
        )
        plt.scatter(
            x_positions2, plot_data2,
            color='blue', marker='o', alpha=0.8,
            facecolors='none', label=sources[1]
        )

        # Format x-axis
        plt.xticks(
            ticks=np.arange(1, i + 1),
            labels=x_labels,
            rotation=45,
            ha='right'
        )

        # Add significance markers
        n = 1
        for p_value in p_values:
            sig = ('****' if p_value < 0.0001 else
                   '***' if p_value < 0.001 else
                   '**' if p_value < 0.01 else
                   '*' if p_value < 0.05 else
                   'ns' if p_value >= 0.5 else '')
            plt.text(
                n + 0.5,
                plt.gca().get_ylim()[1] * 0.96,
                sig,
                fontsize=12
            )
            n += 2

        # Add vertical separators between structures
        for x_coord in np.arange(2.5, i + 0.5, 2):
            plt.axvline(
                x=x_coord,
                ymin=0, ymax=1,
                linestyle='--',
                color='gray',
                linewidth=1
            )

        # Set plot titles and labels
        plt.title(f'{data_type} of {sources[0]} vs {sources[1]}')
        plt.xlabel(plot_type)
        plt.ylabel(f"{data_type} / {plot_type}")
        plt.legend()

        # Clean up plot borders
        ax = plt.gca()
        ax.spines['top'].set_visible(False)
        ax.spines['right'].set_visible(False)

        # Save plot and data
        plot_filename = os.path.join(
            output_folder,
            f'{image_number} {plot_type} scatter plot of {data_type}.png'
        )
        plt.savefig(plot_filename, bbox_inches='tight')
        plt.close()

        data_filename = os.path.join(
            data_for_plot_folder,
            f'{image_number} {plot_type} of {data_type}.csv'
        )
        data_for_plot.to_csv(data_filename, index=False)

        image_number += 1

    return statistics_table


def main():
    # Install required packages if missing
    install_packages()

    # Set up command line argument parser
    parser = argparse.ArgumentParser(
        description="Compare and visualize aggregated ovule data (generated by aggregate_data.py) between two sources.",
        epilog="usage: python compare_and_plot.py <folder1_path> <folder2_path> [output_folder]"
    )
    parser.add_argument(
        "--folder1",
        help="Path to Source1 data folder containing aggregated results (this folder contains python_export_data_aggregated folder)"
    )
    parser.add_argument(
        "--folder2",
        help="Path to Source2 data folder containing aggregated results (this folder contains python_export_data_aggregated folder)"
    )
    parser.add_argument(
        "--output_folder",
        default="",
        help="Output directory path (default: folder1/python_export_data_compared/Source1_vs_Source2)"
    )
    parser.add_argument(
        "--filter",
        type=str,
        default="",
        help="filter out given sample IDs, e.g. 'ID1,ID2' "
    )

    args = parser.parse_args()

    # Load data from both folders
    df1 = get_aggregated_data(args.folder1)
    df2 = get_aggregated_data(args.folder2)

    # Combine data and identify sources
    merged_df = pd.concat([df1, df2], ignore_index=True)
    sources = merged_df['Source'].unique()

    filter_ID_list = []
    if args.filter:
        filter_ID_list = [ID.strip().upper() for ID in args.filter.split(',')]
        merged_df = merged_df[merged_df["sample"].apply(lambda x: str(x).upper() not in filter_ID_list)]

    # Set up output folder
    output_folder = args.output_folder
    if not output_folder:
        output_folder = os.path.join(
            args.folder1,
            "python_export_data_compared",
            f"{sources[0]}_vs_{sources[1]}_filter_[{','.join(filter_ID_list)}]"
        )
    else:
        output_folder = output_folder = os.path.join(output_folder,
            f"{sources[0]}_vs_{sources[1]}")

    # Separate tissue and combined tissue data
    tissue_df = merged_df[merged_df["parent_label"].notna()]
    combine_df = merged_df[merged_df["parent_label"].isna()]

    # Generate plots and statistics
    statistics_table1 = plot_results(tissue_df, 'tissue', sources, output_folder)
    statistics_table2 = plot_results(combine_df, "combine_tissue", sources, output_folder)

    # Combine and save statistics
    statistics_table = pd.concat([statistics_table1, statistics_table2], ignore_index=True)
    stats_filename = os.path.join(
        output_folder,
        f'statistics of {sources[0]} vs {sources[1]}.csv'
    )
    statistics_table.to_csv(stats_filename, index=False)

    # Save merged and sorted data
    selected_columns = [
        'Source', 'sample', 'abbreviation', 'cell number',
        'Volume (μm³)', 'Volume_mean_per_cell (μm³)',
        'Area (μm²)', 'Area_mean_per_cell (μm²)'
    ]
    df_selected = merged_df[selected_columns].sort_values(
        by=['abbreviation', 'cell number']
    )

    merged_filename = os.path.join(
        output_folder,
        f'merge and sorted aggregated data {sources[0]} vs {sources[1]}.csv'
    )
    df_selected.to_csv(merged_filename, index=False)

    current_folder = os.path.basename(output_folder)
    parent_folder = os.path.basename(os.path.dirname(output_folder))
    print(f"\t data and plot saved in {parent_folder}/{current_folder}")


if __name__ == '__main__':
    main()